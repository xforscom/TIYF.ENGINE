name: dataqa-tolerance

on:
  push:
    branches: [ fix/dataqa-tolerance-missing-bars ]
  pull_request:
    branches: [ main ]

jobs:
  matrix:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup .NET 8
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '8.0.x'

      - name: Setup Node.js 20
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Build (Release)
        run: dotnet build -c Release

      - name: Prepare paths
        id: prep
        shell: bash
        run: |
          set -euo pipefail
          ROOT="$(pwd)"
          echo "root=$ROOT" >> $GITHUB_OUTPUT
          echo "sim=$ROOT/src/TiYf.Engine.Sim/bin/Release/net8.0/TiYf.Engine.Sim.dll" >> $GITHUB_OUTPUT
          TOOLS_REL="$ROOT/src/TiYf.Engine.Tools/bin/Release/net8.0/TiYf.Engine.Tools.dll"
          TOOLS_DBG="$ROOT/src/TiYf.Engine.Tools/bin/Debug/net8.0/TiYf.Engine.Tools.dll"
          if [ -f "$TOOLS_REL" ]; then
            echo "tools=$TOOLS_REL" >> $GITHUB_OUTPUT
          elif [ -f "$TOOLS_DBG" ]; then
            echo "tools=$TOOLS_DBG" >> $GITHUB_OUTPUT
          else
            echo "Tools DLL not found in Release or Debug. Listing candidates:" >&2
            ls -la "$ROOT/src/TiYf.Engine.Tools/bin" || true
            ls -la "$ROOT/src/TiYf.Engine.Tools/bin/Release/net8.0" || true
            ls -la "$ROOT/src/TiYf.Engine.Tools/bin/Debug/net8.0" || true
            exit 1
          fi
          echo "cfg=$ROOT/tests/fixtures/backtest_m0/config.backtest-m0.json" >> $GITHUB_OUTPUT

      - name: Run K=1 (pass)
        shell: bash
        run: |
          set -euo pipefail
          root='${{ steps.prep.outputs.root }}'
          sim='${{ steps.prep.outputs.sim }}'
          tools='${{ steps.prep.outputs.tools }}'
          cfg='${{ steps.prep.outputs.cfg }}'
          tmp="$root/.tmp_k1_pass"
          rm -rf "$tmp" && mkdir -p "$tmp"
          export CONFIG_IN="$cfg"
          export CONFIG_OUT="$tmp/config.k1pass.json"
          export TMP_DIR="$tmp"
          export K_MODE="pass"
          export INSTR_FILE="$root/tests/fixtures/backtest_m0/instruments.csv"
          # Node-based preparation: copy ticks, remove 1 data row from each, rewrite config with absolute paths and temp journalDir, force dataQa active
          node - <<'NODE'
          const fs = require('fs');
          const path = require('path');
          const configIn = process.env.CONFIG_IN;
          const configOut = process.env.CONFIG_OUT;
          const tmpDir = process.env.TMP_DIR;
          const kMode = process.env.K_MODE || 'pass';
          const instrumentsFile = process.env.INSTR_FILE;
          if (!configIn || !configOut || !tmpDir || !instrumentsFile) throw new Error('Missing env CONFIG_IN/CONFIG_OUT/TMP_DIR/INSTR_FILE');
          fs.mkdirSync(tmpDir, { recursive: true });
          const cfg = JSON.parse(fs.readFileSync(configIn, 'utf8'));
          // Ensure dataQa active and K=1
          cfg.featureFlags = { ...(cfg.featureFlags||{}), dataQa: 'active' };
          cfg.dataQA = { enabled: true, maxMissingBarsPerInstrument: 1, allowDuplicates: false, spikeZ: 5, repair: { forwardFillBars: 0, dropSpikes: true } };
          // Rewrite instrumentsFile absolute
          cfg.data = cfg.data || {};
          cfg.data.instrumentsFile = path.resolve(instrumentsFile);
          // Process ticks
          if (!cfg.data.ticks || typeof cfg.data.ticks !== 'object') throw new Error('config.data.ticks missing or not an object');
          const rewritten = {};
          // For overflow: create a genuine per-symbol hole: remove 2 from EURUSD only; others remove 0
          const removeNFor = (sym) => (kMode === 'overflow' ? (sym === 'EURUSD' ? 2 : 0) : 1);
          for (const [sym, srcRaw] of Object.entries(cfg.data.ticks)) {
            if (typeof srcRaw !== 'string') continue;
            const src = path.resolve(srcRaw);
            if (!fs.existsSync(src)) throw new Error(`Tick file not found: ${src}`);
            const dst = path.join(tmpDir, `ticks_${sym}.csv`);
            const lines = fs.readFileSync(src, 'utf8').split(/\r?\n/);
            const header = lines[0] ?? '';
            const data = lines.slice(1).filter(l => l.trim().length > 0);
            const toRemove = Math.min(removeNFor(sym), data.length);
            const dataAfter = data.slice(toRemove);
            const out = [header, ...dataAfter].join('\n') + '\n';
            fs.writeFileSync(dst, out, 'utf8');
            // Verify file exists and has >=2 lines (header + at least 1 data row)
            const verify = fs.readFileSync(dst, 'utf8').trim().split(/\r?\n/);
            if (verify.length < 2) {
              console.error(`After K edit, ${dst} has no data rows (lines=${verify.length}).`);
              process.exit(1);
            }
            rewritten[sym] = path.resolve(dst);
          }
          cfg.data.ticks = rewritten;
          // Set temp journalDir
          cfg.output = cfg.output || {};
          cfg.output.journalDir = path.resolve(path.join(tmpDir, 'journals'));
          // Ensure name is backtest-m0 for engine heuristics
          cfg.name = cfg.name || 'backtest-m0';
          fs.writeFileSync(configOut, JSON.stringify(cfg, null, 2), 'utf8');
          // Export CONFIG_OUT for subsequent steps
          fs.appendFileSync(process.env.GITHUB_ENV, `\nCONFIG_OUT=${configOut}\n`);
          fs.appendFileSync(process.env.GITHUB_ENV, `TMP_DIR=${tmpDir}\n`);
          NODE
          # Debug: list temp dir and first 3 lines of each rewritten CSV
          echo "Temp dir listing:" && ls -la "$TMP_DIR"
          for f in "$TMP_DIR"/ticks_*.csv; do echo "== $f =="; head -n 3 "$f"; done
          # Run sim with prepared config
          dotnet exec "$sim" --config "$CONFIG_OUT" --run-id K1-PASS --verbosity quiet
          # Resolve journal paths using config into local variables
          mapfile -t _paths < <(node -e '
            const fs=require("fs"); const path=require("path");
            const cfgPath=process.env.CONFIG_OUT; const runId="M0-RUN-K1-PASS";
            const j=JSON.parse(fs.readFileSync(cfgPath,"utf8"));
            const jdir=(j.output && j.output.journalDir) ? j.output.journalDir : path.resolve("journals","M0");
            const events=path.join(jdir, runId, "events.csv");
            const trades=path.join(jdir, runId, "trades.csv");
            console.log(events); console.log(trades);
          ')
          J_EVENTS="${_paths[0]}"; J_TRADES="${_paths[1]}"
          test -f "$J_EVENTS" || (echo "events missing: $J_EVENTS" && exit 1)
          # Assert summary passed=true and no abort (pure Node)
          EVENTS="$J_EVENTS" node - <<'JS'
          const fs=require("fs");
          const line=(fs.readFileSync(process.env.EVENTS,"utf8").split(/\r?\n/).find(l=>l.includes(",DATA_QA_SUMMARY_V1,"))||"");
          if(!line){ console.error("DATA_QA_SUMMARY_V1 not found"); process.exit(1); }
          const QUOTE=String.fromCharCode(34);
          function splitCsv(s){ const out=[]; let buf="", q=false; for(let i=0;i<s.length;i++){ const c=s[i]; if(q){ if(c===QUOTE){ if(i+1<s.length && s[i+1]===QUOTE){ buf+=QUOTE; i++; } else { q=false; } } else { buf+=c; } } else { if(c===','){ out.push(buf); buf=""; } else if(c===QUOTE){ q=true; } else { buf+=c; } } } out.push(buf); return out; }
          const cols=splitCsv(line);
          const payload=cols[3];
          try {
            const j=JSON.parse(payload);
            if(!(j.passed===true && j.aborted===false)){ console.error("Unexpected DATA_QA_SUMMARY_V1", j); process.exit(1); }
          } catch(e) {
            console.error("Failed to parse payload as JSON:", payload); process.exit(1);
          }
          JS
          EVENTS="$J_EVENTS" node - <<'JS'
          const fs=require('fs');
          const text=fs.readFileSync(process.env.EVENTS,'utf8');
          if (text.includes(',DATA_QA_ABORT_V1,')) { console.error('Unexpected abort event found'); process.exit(1); }
          JS
          # Strict verify (deep)
          dotnet exec "$tools" verify strict --events "$J_EVENTS" --trades "$J_TRADES" --schema 1.3.0 --json

      - name: Run K=1 with overflow (fail)
        shell: bash
        run: |
          set -euo pipefail
          root='${{ steps.prep.outputs.root }}'
          sim='${{ steps.prep.outputs.sim }}'
          tools='${{ steps.prep.outputs.tools }}'
          cfg='${{ steps.prep.outputs.cfg }}'
          tmp="$root/.tmp_k1_over"
          rm -rf "$tmp" && mkdir -p "$tmp"
          export CONFIG_IN="$cfg"
          export CONFIG_OUT="$tmp/config.k1over.json"
          export TMP_DIR="$tmp"
          export K_MODE="overflow"
          export INSTR_FILE="$root/tests/fixtures/backtest_m0/instruments.csv"
          node - <<'NODE'
          const fs = require('fs');
          const path = require('path');
          const configIn = process.env.CONFIG_IN;
          const configOut = process.env.CONFIG_OUT;
          const tmpDir = process.env.TMP_DIR;
          const kMode = process.env.K_MODE || 'overflow';
          const instrumentsFile = process.env.INSTR_FILE;
          if (!configIn || !configOut || !tmpDir || !instrumentsFile) throw new Error('Missing env CONFIG_IN/CONFIG_OUT/TMP_DIR/INSTR_FILE');
          fs.mkdirSync(tmpDir, { recursive: true });
          const cfg = JSON.parse(fs.readFileSync(configIn, 'utf8'));
          cfg.featureFlags = { ...(cfg.featureFlags||{}), dataQa: 'active' };
          cfg.dataQA = { enabled: true, maxMissingBarsPerInstrument: 1, allowDuplicates: false, spikeZ: 5, repair: { forwardFillBars: 0, dropSpikes: true } };
          cfg.data = cfg.data || {};
          cfg.data.instrumentsFile = path.resolve(instrumentsFile);
          if (!cfg.data.ticks || typeof cfg.data.ticks !== 'object') throw new Error('config.data.ticks missing or not an object');
          const rewritten = {};
          const removeN = kMode === 'overflow' ? 2 : 1;
          for (const [sym, srcRaw] of Object.entries(cfg.data.ticks)) {
            if (typeof srcRaw !== 'string') continue;
            const src = path.resolve(srcRaw);
            if (!fs.existsSync(src)) throw new Error(`Tick file not found: ${src}`);
            const dst = path.join(tmpDir, `ticks_${sym}.csv`);
            const lines = fs.readFileSync(src, 'utf8').split(/\r?\n/);
            const header = lines[0] ?? '';
            const data = lines.slice(1).filter(l => l.trim().length > 0);
            const toRemove = Math.min(removeN, data.length);
            const dataAfter = data.slice(toRemove);
            const out = [header, ...dataAfter].join('\n') + '\n';
            fs.writeFileSync(dst, out, 'utf8');
            const verify = fs.readFileSync(dst, 'utf8').trim().split(/\r?\n/);
            if (verify.length < 2) {
              console.error(`After K edit, ${dst} has no data rows (lines=${verify.length}).`);
              process.exit(1);
            }
            rewritten[sym] = path.resolve(dst);
          }
          cfg.data.ticks = rewritten;
          cfg.output = cfg.output || {};
          cfg.output.journalDir = path.resolve(path.join(tmpDir, 'journals'));
          cfg.name = cfg.name || 'backtest-m0';
          fs.writeFileSync(configOut, JSON.stringify(cfg, null, 2), 'utf8');
          fs.appendFileSync(process.env.GITHUB_ENV, `\nCONFIG_OUT=${configOut}\n`);
          fs.appendFileSync(process.env.GITHUB_ENV, `TMP_DIR=${tmpDir}\n`);
          NODE
          # Debug: list temp dir and first 3 lines of each rewritten CSV
          echo "Temp dir listing:" && ls -la "$TMP_DIR"
          for f in "$TMP_DIR"/ticks_*.csv; do echo "== $f =="; head -n 3 "$f"; done
          # Run sim with prepared config
          dotnet exec "$sim" --config "$CONFIG_OUT" --run-id K1-FAIL --verbosity quiet
          # Resolve journal paths using config into local variables
          mapfile -t _paths < <(node -e '
            const fs=require("fs"); const path=require("path");
            const cfgPath=process.env.CONFIG_OUT; const runId="M0-RUN-K1-FAIL";
            const j=JSON.parse(fs.readFileSync(cfgPath,"utf8"));
            const jdir=(j.output && j.output.journalDir) ? j.output.journalDir : path.resolve("journals","M0");
            const events=path.join(jdir, runId, "events.csv");
            const trades=path.join(jdir, runId, "trades.csv");
            console.log(events); console.log(trades);
          ')
          J_EVENTS="${_paths[0]}"; J_TRADES="${_paths[1]}"
          test -f "$J_EVENTS" || (echo "events missing: $J_EVENTS" && exit 1)
          # Assert summary passed=false (pure Node)
          EVENTS="$J_EVENTS" node - <<'JS'
          const fs=require("fs");
          const line=(fs.readFileSync(process.env.EVENTS,"utf8").split(/\r?\n/).find(l=>l.includes(",DATA_QA_SUMMARY_V1,"))||"");
          if(!line){ console.error("DATA_QA_SUMMARY_V1 not found"); process.exit(1); }
          const QUOTE=String.fromCharCode(34);
          function splitCsv(s){ const out=[]; let buf="", q=false; for(let i=0;i<s.length;i++){ const c=s[i]; if(q){ if(c===QUOTE){ if(i+1<s.length && s[i+1]===QUOTE){ buf+=QUOTE; i++; } else { q=false; } } else { buf+=c; } } else { if(c===','){ out.push(buf); buf=""; } else if(c===QUOTE){ q=true; } else { buf+=c; } } } out.push(buf); return out; }
          const cols=splitCsv(line);
          const payload=cols[3];
          try {
            const j=JSON.parse(payload);
            if(j.passed!==false){ console.error("Expected passed=false in DATA_QA_SUMMARY_V1", j); process.exit(1); }
          } catch(e) {
            console.error("Failed to parse payload as JSON:", payload); process.exit(1);
          }
          JS
          # Strict verify (JSON may be ok or 2; we tolerate non-zero here as long as it runs)
          tools_out=0; dotnet exec "$tools" verify strict --events "$J_EVENTS" --trades "$J_TRADES" --schema 1.3.0 --json || tools_out=$?; if [ "$tools_out" -ne 0 ] && [ "$tools_out" -ne 2 ]; then exit 1; fi
